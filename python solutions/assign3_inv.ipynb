{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "input_dim = 6\n",
    "hidden_dims = [128, 64]  # Two hidden layers with 128 and 64 units\n",
    "output_dim = 40\n",
    "\n",
    "# Initialize the model\n",
    "model = MultiLayerNN(input_dim, hidden_dims, output_dim)\n",
    "\n",
    "# Train the last layer weights using Moore-Penrose pseudo inverse\n",
    "model.train_last_layer(X_train, Y_train)\n",
    "\n",
    "# Create multiple models and average their predictions\n",
    "num_models = 10\n",
    "models = []\n",
    "\n",
    "# Train multiple models\n",
    "for _ in range(num_models):\n",
    "    temp_model = MultiLayerNN(input_dim, hidden_dims, output_dim)\n",
    "    temp_model.train_last_layer(X_train, Y_train)\n",
    "    models.append(temp_model)\n",
    "\n",
    "# Function to average predictions\n",
    "def average_predictions(models, X):\n",
    "    predictions = [model.predict(X) for model in models]\n",
    "    return torch.mean(torch.stack(predictions), dim=0)\n",
    "\n",
    "# Predict on the test set\n",
    "avg_predictions = average_predictions(models, X_test)\n",
    "\n",
    "\n",
    "# Select 10 random test samples\n",
    "indices = np.random.choice(range(X_test.shape[0]), 10, replace=False)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, idx in enumerate(indices):\n",
    "    plt.subplot(5, 2, i + 1)\n",
    "    plt.plot(Y_test[idx].numpy(), label=\"True Gains\")\n",
    "    plt.plot(avg_predictions[idx].detach().numpy(), label=\"Predicted Gains\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Sample {idx}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute prediction error\n",
    "errors = Y_test - avg_predictions\n",
    "errors = errors.detach().numpy().flatten()\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(errors, bins=50, alpha=0.7, color=\"blue\", label=\"Prediction Errors\")\n",
    "plt.xlabel(\"Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Prediction Errors\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Compute Mean Squared Error on the test set\n",
    "mse = torch.mean((avg_predictions - Y_test) ** 2)\n",
    "print(f\"Mean Squared Error on Test Set: {mse.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = Gain_cell\n",
    "Y = Raman_training\n",
    "\n",
    "X_test, X_train, Y_test, Y_train = train_test_split(X, Y, test_size=0.4, random_state=42)\n",
    "X_test.shape, X_train.shape , Y_test.shape, Y_train.shape\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "X_train_inv = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_inv = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "Y_train_inv = torch.tensor(Y_train, dtype=torch.float32)\n",
    "Y_test_inv = torch.tensor(Y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerNN_inverse:\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.hidden_weights = [torch.randn(input_dim if i == 0 else hidden_dims[i - 1], hidden_dims[i]) for i in range(len(hidden_dims))]\n",
    "        self.hidden_biases = [torch.randn(1, hidden_dims[i]) for i in range(len(hidden_dims))]\n",
    "        self.output_weights = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        activations = X\n",
    "        for W, b in zip(self.hidden_weights, self.hidden_biases):\n",
    "            activations = torch.relu(torch.matmul(activations, W) + b)\n",
    "        return activations\n",
    "\n",
    "    def train_last_layer(self, X, Y):\n",
    "        hidden_output = self.forward(X)\n",
    "        pseudo_inverse = torch.pinverse(hidden_output)\n",
    "        self.output_weights = torch.matmul(pseudo_inverse, Y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        hidden_output = self.forward(X)\n",
    "        return torch.matmul(hidden_output, self.output_weights)\n",
    "\n",
    "# Train multiple models for model averaging\n",
    "num_models = 10\n",
    "models = []\n",
    "\n",
    "for _ in range(num_models):\n",
    "    model = MultiLayerNN(input_dim=40, hidden_dims=[64, 64], output_dim=6)\n",
    "    model.train_last_layer(X_train_inv, Y_train_inv)\n",
    "    models.append(model)\n",
    "\n",
    "# Model averaging function\n",
    "def average_predictions(models, X):\n",
    "    predictions = [model.predict(X) for model in models]\n",
    "    return torch.mean(torch.stack(predictions), dim=0)\n",
    "\n",
    "# Test predictions\n",
    "avg_predictions = average_predictions(models, X_test_inv)  \n",
    "\n",
    "predictions = model.predict(X_test_inv)\n",
    "print(\"Test RMSE:\", torch.sqrt(torch.mean((predictions - Y_test_inv) ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the hstack and split the dataset column-wise\n",
    "Raman_power_reversed = Raman_training[:, :3]\n",
    "Raman_wavelength_reversed = Raman_training[:, 3:6]\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "df_power_reversed = pd.DataFrame(Raman_power_reversed, columns=['Power1', 'Power2', 'Power3'])\n",
    "df_wavelength_reversed = pd.DataFrame(Raman_wavelength_reversed, columns=['Wavelength1', 'Wavelength2', 'Wavelength3'])\n",
    "\n",
    "df_pump1 = Raman_power['Power 2']\n",
    "print(df_pump1.head())\n",
    "\n",
    "df_pump1_pred = Raman_power_reversed[:, 1]\n",
    "df_pump1_pred = pd.DataFrame(df_pump1_pred, columns=['Predicted Power 1'])\n",
    "print(df_pump1_pred.head())\n",
    "\n",
    "plt.scatter(df_pump1, df_pump1_pred, alpha=0.5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
